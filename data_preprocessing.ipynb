{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:24:13.213682Z",
     "iopub.status.busy": "2022-12-01T11:24:13.213088Z",
     "iopub.status.idle": "2022-12-01T11:24:17.706890Z",
     "shell.execute_reply": "2022-12-01T11:24:17.705623Z",
     "shell.execute_reply.started": "2022-12-01T11:24:13.213582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.23.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.8.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (5.2.1)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:16:09.546923Z",
     "iopub.status.busy": "2022-12-01T14:16:09.545822Z",
     "iopub.status.idle": "2022-12-01T14:16:12.397153Z",
     "shell.execute_reply": "2022-12-01T14:16:12.396270Z",
     "shell.execute_reply.started": "2022-12-01T14:16:09.546801Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from modules.TextCleaner import Cleaner\n",
    "from modules.TextPreparation import TextPreparation\n",
    "import regex as re\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:16:13.654716Z",
     "iopub.status.busy": "2022-12-01T14:16:13.653768Z",
     "iopub.status.idle": "2022-12-01T14:16:13.659796Z",
     "shell.execute_reply": "2022-12-01T14:16:13.659171Z",
     "shell.execute_reply.started": "2022-12-01T14:16:13.654675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:16:16.552828Z",
     "iopub.status.busy": "2022-12-01T14:16:16.551000Z",
     "iopub.status.idle": "2022-12-01T14:16:17.244063Z",
     "shell.execute_reply": "2022-12-01T14:16:17.243403Z",
     "shell.execute_reply.started": "2022-12-01T14:16:16.552759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 3)\n",
      "                                                text  stars  sentiment\n",
      "0  Total bill for this horrible service? Over $8G...    1.0          0\n",
      "1  I *adore* Travis at the Hard Rock's new Kelly ...    5.0          1\n",
      "2  I have to say that this office really has it t...    5.0          1\n"
     ]
    }
   ],
   "source": [
    "# load in dataframe\n",
    "df = pd.read_csv('data/yelp_ratings.csv').iloc[0:35000, :]\n",
    "df_end_test = pd.read_csv('data/yelp_ratings.csv').iloc[35000:37000, :]\n",
    "print(df.shape)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:16:19.964711Z",
     "iopub.status.busy": "2022-12-01T14:16:19.964013Z",
     "iopub.status.idle": "2022-12-01T14:16:29.758672Z",
     "shell.execute_reply": "2022-12-01T14:16:29.757532Z",
     "shell.execute_reply.started": "2022-12-01T14:16:19.964685Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean texts and assess how many tokens in each text\n",
    "\n",
    "split_ratio = 0.8\n",
    "\n",
    "cleaner = Cleaner()\n",
    "textPrepare = TextPreparation()\n",
    "df['cleaned_text'] = df['text'].apply(lambda x : cleaner.clean_text(x))\n",
    "train_df, test_df = textPrepare.split_data(df, split_ratio)\n",
    "\n",
    "#df['text_lens'] = df['cleaned_text'].apply(lambda x : len(x))\n",
    "#sorted_lens = np.sort(df['text_lens'])\n",
    "#plt.figure(figsize=(15, 8))\n",
    "#plt.plot(np.arange(0, 100, 100/len(sorted_lens)), sorted_lens)\n",
    "#plt.xlabel('Percent texts')\n",
    "#plt.ylabel('Num tokens')\n",
    "#plt.grid()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:16:29.761150Z",
     "iopub.status.busy": "2022-12-01T14:16:29.760182Z",
     "iopub.status.idle": "2022-12-01T14:16:52.878138Z",
     "shell.execute_reply": "2022-12-01T14:16:52.877200Z",
     "shell.execute_reply.started": "2022-12-01T14:16:29.761123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sentences: 218826\n"
     ]
    }
   ],
   "source": [
    "# extract sentences and create word embeddings\n",
    "\n",
    "emb_size = 90\n",
    "w_size = 2\n",
    "min_count = 1\n",
    "save = True\n",
    "\n",
    "embeddings = textPrepare.create_word_embeddings(train_df, emb_size, w_size, min_count, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:16:52.879550Z",
     "iopub.status.busy": "2022-12-01T14:16:52.879214Z",
     "iopub.status.idle": "2022-12-01T14:17:02.947477Z",
     "shell.execute_reply": "2022-12-01T14:17:02.946568Z",
     "shell.execute_reply.started": "2022-12-01T14:16:52.879524Z"
    }
   },
   "outputs": [],
   "source": [
    "# vectorise texts with embeddings and rebalance\n",
    "\n",
    "tokens_len = 150\n",
    "\n",
    "train_df['vectorised_texts'] = train_df['cleaned_text'].apply(lambda x, embeddings=embeddings, tokens_len=tokens_len: \n",
    "                                                    textPrepare.vectorise_texts(x, embeddings, tokens_len))\n",
    "test_df['vectorised_texts'] = test_df['cleaned_text'].apply(lambda x, embeddings=embeddings, tokens_len=tokens_len: \n",
    "                                                    textPrepare.vectorise_texts(x, embeddings, tokens_len))\n",
    "train_df = textPrepare.rebalance(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:17:02.950363Z",
     "iopub.status.busy": "2022-12-01T14:17:02.949676Z",
     "iopub.status.idle": "2022-12-01T14:17:08.136101Z",
     "shell.execute_reply": "2022-12-01T14:17:08.135125Z",
     "shell.execute_reply.started": "2022-12-01T14:17:02.950329Z"
    }
   },
   "outputs": [],
   "source": [
    "#compress texts into vectors\n",
    "train_df['compressed_texts'] = train_df['vectorised_texts'].apply(lambda x: textPrepare.compress_texts(x))\n",
    "test_df['compressed_texts'] = test_df['vectorised_texts'].apply(lambda x: textPrepare.compress_texts(x))\n",
    "train_df = train_df.dropna(axis=0)\n",
    "test_df = test_df.dropna(axis=0)\n",
    "\n",
    "# extract data from df into numpy format\n",
    "X_train = np.zeros((train_df.shape[0], emb_size))\n",
    "X_test = np.zeros((test_df.shape[0], emb_size))\n",
    "for i in range(train_df.shape[0]):\n",
    "    X_train[i, :] = train_df.iloc[i, -1]\n",
    "    if i < test_df.shape[0]:\n",
    "        X_test[i, :] = test_df.iloc[i, -1]\n",
    "y_train = np.reshape(np.array(train_df['sentiment']), (len(train_df), 1))\n",
    "y_test = np.reshape(np.array(test_df['sentiment']), (len(test_df), 1))\n",
    "train = np.append(X_train, y_train, axis=1)\n",
    "test = np.append(X_test, y_test, axis=1)\n",
    "train = train[~np.isnan(train).any(axis=1), :]\n",
    "test = test[~np.isnan(test).any(axis=1), :]\n",
    "\n",
    "with open('data/train_fcnn', 'wb') as fp:\n",
    "    pickle.dump(train, fp)\n",
    "with open('data/test_fcnn', 'wb') as fp:\n",
    "    pickle.dump(test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:25:02.094543Z",
     "iopub.status.busy": "2022-12-01T11:25:02.093572Z",
     "iopub.status.idle": "2022-12-01T11:25:39.825519Z",
     "shell.execute_reply": "2022-12-01T11:25:39.824359Z",
     "shell.execute_reply.started": "2022-12-01T11:25:02.094502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 150, 91)\n",
      "(41806, 150, 91)\n"
     ]
    }
   ],
   "source": [
    "# extract data from df into numpy format and append to labels\n",
    "\n",
    "X_train_trans = np.zeros((train_df.shape[0], tokens_len, emb_size))\n",
    "X_test_trans = np.zeros((test_df.shape[0], tokens_len, emb_size))\n",
    "\n",
    "for i in range(train_df.shape[0]):\n",
    "    X_train_trans[i, :, :] = train_df.iloc[i, -2]\n",
    "    if i < test_df.shape[0]:\n",
    "        X_test_trans[i, :, :] = test_df.iloc[i, -2]\n",
    "\n",
    "#y_train_trans = np.array(train_df['sentiment'])\n",
    "#y_test_trans = np.array(test_df['sentiment'])\n",
    "\n",
    "#train_trans = np.append(X_train_trans, np.tile(np.reshape(y_train_trans, (len(y_train_trans), 1, 1)), (1, tokens_len, 1)), axis=2)\n",
    "#test_trans = np.append(X_test_trans, np.tile(np.reshape(y_test_trans, (len(y_test_trans), 1, 1)), (1, tokens_len, 1)), axis=2)\n",
    "\n",
    "y_train_trans = np.empty((X_train_trans.shape[0], tokens_len))\n",
    "y_test_trans = np.empty((X_test_trans.shape[0], tokens_len))\n",
    "y_train_trans[...] = np.reshape(np.array(train_df['sentiment']), (X_train_trans.shape[0], 1))\n",
    "y_test_trans[...] = np.reshape(np.array(test_df['sentiment']), (X_test_trans.shape[0], 1))\n",
    "\n",
    "train_trans = np.empty((X_train_trans.shape[0], tokens_len, emb_size + 1))\n",
    "test_trans = np.empty((X_test_trans.shape[0], tokens_len, emb_size + 1))\n",
    "train_trans[:, :, 0:-1] = X_train_trans\n",
    "train_trans[:, :, -1] = y_train_trans\n",
    "test_trans[:, :, 0:-1] = X_test_trans\n",
    "test_trans[:, :, -1] = y_test_trans\n",
    "\n",
    "print(test_trans.shape)\n",
    "print(train_trans.shape)\n",
    "\n",
    "with open('data/train_trans', 'wb') as fp:\n",
    "    pickle.dump(train_trans, fp)\n",
    "with open('data/test_trans', 'wb') as fp:\n",
    "    pickle.dump(test_trans, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:25:39.826830Z",
     "iopub.status.busy": "2022-12-01T11:25:39.826579Z",
     "iopub.status.idle": "2022-12-01T11:25:40.168453Z",
     "shell.execute_reply": "2022-12-01T11:25:40.167108Z",
     "shell.execute_reply.started": "2022-12-01T11:25:39.826806Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/test_dataset', 'wb') as fp:\n",
    "    pickle.dump(df_end_test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
