{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T13:58:13.095102Z",
     "iopub.status.busy": "2022-12-01T13:58:13.094044Z",
     "iopub.status.idle": "2022-12-01T13:58:15.951169Z",
     "shell.execute_reply": "2022-12-01T13:58:15.950148Z",
     "shell.execute_reply.started": "2022-12-01T13:58:13.095018Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from modules.TextCleaner import Cleaner\n",
    "from modules.TextPreparation import TextPreparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T13:58:18.688525Z",
     "iopub.status.busy": "2022-12-01T13:58:18.687917Z",
     "iopub.status.idle": "2022-12-01T13:58:18.694476Z",
     "shell.execute_reply": "2022-12-01T13:58:18.693356Z",
     "shell.execute_reply.started": "2022-12-01T13:58:18.688495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T13:58:21.168344Z",
     "iopub.status.busy": "2022-12-01T13:58:21.167804Z",
     "iopub.status.idle": "2022-12-01T13:58:25.395157Z",
     "shell.execute_reply": "2022-12-01T13:58:25.394398Z",
     "shell.execute_reply.started": "2022-12-01T13:58:21.168307Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload train and test sets back in\n",
    "\n",
    "with open('data/train_trans', 'rb') as handle:\n",
    "    train = pickle.load(handle)\n",
    "with open('data/test_trans', 'rb') as handle:\n",
    "    test = pickle.load(handle)\n",
    "with open('data/embeddings', 'rb') as handle:\n",
    "    embeddings = pickle.load(handle)\n",
    "with open('data/test_dataset', 'rb') as handle:\n",
    "    df_end_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:11:25.316394Z",
     "iopub.status.busy": "2022-12-01T14:11:25.316005Z",
     "iopub.status.idle": "2022-12-01T14:11:25.326911Z",
     "shell.execute_reply": "2022-12-01T14:11:25.326084Z",
     "shell.execute_reply.started": "2022-12-01T14:11:25.316368Z"
    }
   },
   "outputs": [],
   "source": [
    "## not used as using pytorch built in encoder ##\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, tokens_len, emb_size, num_heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.tokens_len = tokens_len\n",
    "        self.num_heads = num_heads\n",
    "        self.mha = nn.MultiheadAttention(self.emb_size, \n",
    "                                        self.num_heads, \n",
    "                                        dropout=0.1, \n",
    "                                        batch_first=True\n",
    "                                        )\n",
    "        self.fc1 = nn.Linear(self.emb_size, self.emb_size * 4)\n",
    "        self.fc2 = nn.Linear(self.emb_size * 4, self.emb_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layernorm = nn.LayerNorm(self.emb_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.layernorm(self.mha(x, x, x)[0] + x)\n",
    "        x = self.layernorm(self.fc2(self.relu(self.fc1(x))) + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(EncoderLayer):\n",
    "    def __init__(self, tokens_len, emb_size, num_heads):\n",
    "        super().__init__(tokens_len, emb_size, num_heads)\n",
    "        self.emb_size = emb_size\n",
    "        self.tokens_len = tokens_len\n",
    "        self.num_heads = num_heads\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=self.emb_size, \n",
    "                                                        nhead=self.num_heads, \n",
    "                                                        dim_feedforward=self.emb_size * 6,\n",
    "                                                        dropout=0.1,\n",
    "                                                        batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
    "        self.fc1 = nn.Linear(self.emb_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        #x = torch.sum(x, axis=1) / self.tokens_len\n",
    "        x = self.fc1(x[:, 0, :])\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:11:40.031252Z",
     "iopub.status.busy": "2022-12-01T14:11:40.030908Z",
     "iopub.status.idle": "2022-12-01T14:13:23.247315Z",
     "shell.execute_reply": "2022-12-01T14:13:23.246542Z",
     "shell.execute_reply.started": "2022-12-01T14:11:40.031227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per text at epoch number 1 : 0.733791\n",
      "Average loss per text at epoch number 2 : 0.226435\n",
      "Average loss per text at epoch number 3 : 0.205577\n",
      "Average loss per text at epoch number 4 : 0.193431\n"
     ]
    }
   ],
   "source": [
    "# train transformer\n",
    "\n",
    "torch.manual_seed(200206323)\n",
    "emb_size = train.shape[-1] - 1\n",
    "tokens_len = train.shape[1]\n",
    "max_epochs = 5\n",
    "epoch_print_num = 1\n",
    "batch_size = 400\n",
    "num_heads = 9\n",
    "criterion = nn.BCELoss()\n",
    "textPrepare = TextPreparation()\n",
    "positions = textPrepare.create_pos_encodings(emb_size).float()\n",
    "transformer = Transformer(  emb_size=emb_size, \n",
    "                            tokens_len=tokens_len, \n",
    "                            num_heads=num_heads,\n",
    "                        ).to(device)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.002, weight_decay=0.0000001)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "running_loss = 0\n",
    "for epoch in range(max_epochs):\n",
    "    for batch in trainloader:\n",
    "        y_batch = batch[:, 0, -1].to(device)\n",
    "        if len(y_batch) != batch_size:\n",
    "            continue\n",
    "        x_batch = batch[:, :, 0:-1] + positions[0, 0:tokens_len, :]\n",
    "        x_batch = x_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        estimate = torch.squeeze(transformer.forward(x_batch.clone().detach().requires_grad_(True).float()))\n",
    "        loss = criterion(estimate, y_batch.clone().detach().requires_grad_(True).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        running_loss += loss\n",
    "    if epoch % epoch_print_num == 0 and epoch > 0:\n",
    "        ave_loss = round(running_loss / (epoch_print_num * (train.shape[0] / batch_size)), 6)\n",
    "        print(f'Average loss per text at epoch number {epoch} : {ave_loss}')\n",
    "        running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:13:23.248935Z",
     "iopub.status.busy": "2022-12-01T14:13:23.248684Z",
     "iopub.status.idle": "2022-12-01T14:13:24.813534Z",
     "shell.execute_reply": "2022-12-01T14:13:24.812454Z",
     "shell.execute_reply.started": "2022-12-01T14:13:23.248911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "# test on test set\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=test.shape[0], shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for batch in testloader:\n",
    "        x_batch = batch[:, :, 0:-1] + positions[0, 0:tokens_len, :]\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = batch[:, 0, -1]\n",
    "        estimate = np.array(transformer.eval().forward(x_batch.clone().detach().float()).cpu())\n",
    "accuracy = round(accuracy_score(y_batch, np.around(estimate, 0)), 2)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:13:58.575974Z",
     "iopub.status.busy": "2022-12-01T14:13:58.575515Z",
     "iopub.status.idle": "2022-12-01T14:13:58.581982Z",
     "shell.execute_reply": "2022-12-01T14:13:58.580930Z",
     "shell.execute_reply.started": "2022-12-01T14:13:58.575941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AH-mazing pizza!\n",
      "I hosted a corporate meeting a while back in April 2016 and ordered pizza from Payless Pizza 2  I was dubious until the first bite! Now that was a great pizza.! The people attending the meeting took some back to their hotels and asked to have the leftovers for lunch the next day! \n",
      "Since that time every time a member of the company visits town they ask for \"that awesome pizza\" Courteous staff, well priced, fast and DELICIOUS!   The best thing is the consistency of their product.  Its always tastes the same which is also Ah-mazing! ;-)\n"
     ]
    }
   ],
   "source": [
    "# select a sentence from the dataset\n",
    "\n",
    "sentence = df_end_test.iloc[500, 0]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:14:04.248067Z",
     "iopub.status.busy": "2022-12-01T14:14:04.247698Z",
     "iopub.status.idle": "2022-12-01T14:14:04.263001Z",
     "shell.execute_reply": "2022-12-01T14:14:04.261624Z",
     "shell.execute_reply.started": "2022-12-01T14:14:04.248034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sentence: 96\n",
      "Classified as GOOD review. Certainty: 0.9883999824523926\n"
     ]
    }
   ],
   "source": [
    "# test on custom sentences\n",
    "x = sentence\n",
    "\n",
    "cleaner = Cleaner()\n",
    "x_cleaned = cleaner.clean_text(x)\n",
    "print(f'length of sentence: {len(x_cleaned)}')\n",
    "x_vectorised = np.reshape(textPrepare.vectorise_texts(x_cleaned, embeddings, tokens_len), (1, tokens_len, emb_size))\n",
    "sampleloader = torch.utils.data.DataLoader(x_vectorised, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for batch in sampleloader:\n",
    "        batch = batch.to(device)\n",
    "        #x1 = torch.sum(batch, axis=1)\n",
    "        #estimate1 = np.array(neuralnet.eval().forward(x1.clone().detach().float()))[0][0]\n",
    "        estimate2 = np.array(transformer.eval().forward(batch.clone().detach().float()).cpu())[0][0]\n",
    "        if estimate2 >= 0.5:\n",
    "            print(f'Classified as GOOD review. Certainty: {round(max([estimate2, 1 - estimate2]), 4)}')\n",
    "        else:\n",
    "            print(f'Classified as BAD review. Certainty: {round(max([estimate2, 1 - estimate2]), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
